<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>MSc - Data Mining</title>

    <!-- Bootstrap core CSS -->
    <link href="../../../style/bootstrap/css/bootstrap.min.css" rel="stylesheet">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../../style/codehilite/css/default.css" rel="stylesheet">
    <link href="../../../style/misc/css/module.css" rel="stylesheet">
    <link href="../../../style/misc/css/practical.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

	<script type="text/javascript"
	  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>

  </head>

<body>

	<!-- Fixed navbar -->
	<div class="navbar navbar-default navbar-fixed-top" role="navigation">
		<div class="container">
			
			
	    	<div class="collapse navbar-collapse">
	      		<ul class="nav navbar-nav navbar-right">
		
					<!-- module home -->
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="../../../index.html"><span class="glyphicon glyphicon-home"></span></a>
						</div>						
					</li>
					
					<!-- topics -->
	        		<li>
						<div class="navbar-collapse collapse" id="b">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span class="glyphicon glyphicon-list-alt"></span>
									</a>
									<ul class="dropdown-menu" role="menu">
										<li class="dropdown-header">Topics</li>
										
										<li >
											<a href="../../../topics/01-Module_Overview/index.html">Module Overview</a>
										</li>
										
										<li class="active">
											<a href="../../../topics/02-Data_Handling/index.html">Data Handling</a>
										</li>
										
										<li >
											<a href="../../../topics/03-Exploratory_Data_Analysis/index.html">Exploratory Data Analysis</a>
										</li>
										
										<li >
											<a href="../../../topics/04-Data_Modelling_Introduction/index.html">Data Modelling Introduction</a>
										</li>
										
										<li >
											<a href="../../../topics/05-Regression/index.html">Regression</a>
										</li>
										
										<li >
											<a href="../../../topics/06-Classification_1/index.html">Classification 1</a>
										</li>
										
										<li >
											<a href="../../../topics/07-Data_Modelling_Advanced/index.html">Data Modelling Advanced</a>
										</li>
										
										<li >
											<a href="../../../topics/08-Classification_2/index.html">Classification 2</a>
										</li>
										
										<li >
											<a href="../../../topics/09-Clustering/index.html">Clustering</a>
										</li>
										
										<li >
											<a href="../../../topics/10-Association_Analysis/index.html">Association Analysis</a>
										</li>
										
										<li >
											<a href="../../../topics/11-Anomaly_Detection_and_Recommendation_Systems/index.html">Anomaly Detection and Recommendation Systems</a>
										</li>
										
										<li >
											<a href="../../../topics/12-Deep_Learning/index.html">Deep Learning</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li>

					<!-- resources -->
	        		<li>
						<div class="navbar-collapse collapse" id="b">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span class="glyphicon glyphicon-th-list"></span>
									</a>
									<ul class="dropdown-menu" role="menu">
										<li class="dropdown-header">Resources</li>
										
										<li >
											<a href="../../../topics/02-Data_Handling/index.html#01-Data-Storage">Data-Storage</a>
										</li>
										
										<li >
											<a href="../../../topics/02-Data_Handling/index.html#02-Big-Data-Frameworks">Big-Data-Frameworks</a>
										</li>
										
										<li class="active">
											<a href="../../../topics/02-Data_Handling/index.html#03-Practical">Practical</a>
										</li>
										
										<li >
											<a href="../../../topics/02-Data_Handling/index.html#04-Resources">Resources</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li>
								
					<!-- pages-->
	        		<li>
						<div class="navbar-collapse collapse" id="c">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span>spark</span
									</a>
									<ul class="dropdown-menu" role="menu">
										
										<li >
											<a href="00-Outline.html">Outline</a>
										</li>
										
										<li class="active">
											<a href="01-spark.html">spark</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li> 
					
	        	</ul>
			</div>
		</div>
	</div>

	<!-- contents -->
	<div class="container">
		
		<ul class="pager">
			
			<li class="previous"><a href="00-Outline.html">&larr; Previous (Outline)</a></li>
			
			
			
			<li class="next disabled"><a>Next &rarr;</a></li>
			
		</ul>
		
		<h1>Installing Spark</h1>
<p>Most of the following installation notes apply to machines running a Unix-based operating system (such as Linux or Macos).</p>
<p>For MS Windows machines, the procedure is slightly more complex. However, <a href="https://phoenixnap.com/kb/install-spark-on-windows-10">this guide</a> goes through all the necessary steps. For Windows users, that guide should be followed with the following exceptions:</p>
<ol>
<li>The Spark version we use is Spark 3.0.1, compiled with Scala 2.12 and prebuilt for Apache Hadoop 3.2 and later.</li>
<li>After a Java 8 JVM has been installed, it does not seem to be necessary to install Scala too - the Spark installation seems to have as much Scala as it needs</li>
<li>You have already installed python using either Anaconda or Miniconda. You should just ensure that it has been activated using 'conda activate`.</li>
</ol>
<p>For other users, the procedure is as follows.</p>
<h2>Choose latest stable version</h2>
<p>From the dropdown, use <code>Spark Release 3.0.1 (Sep 02) 2020</code> and <code>Pre-built for Apache Hadoop 3.2 and later</code>.</p>
<p>If you prefer, you can just download the <a href="https://ftp.heanet.ie/mirrors/www.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz">archive directly from the nearest Apache mirror site for users based in Ireland</a>. If you are not based in Ireland, it is probably better to leave Apache to suggest a mirror site that is nearer your location.</p>
<p>It is also a good idea to download the check files (particularly the relevant sha512 digests) to check the integrity of the file (that it has not been corrupted during download) and also that the file that has been offered for download is the one signed by the official developers. </p>
<h2>Install pyspark</h2>
<p>Spark was designed with the Scala language in mind, but we use python in this
module. Hence we suggest that the <code>pyspark</code> module is used to bridge between
the Spark/scala world and the python programs and tools we use in this module.
With pyspark in place, Spark can be called from python (the default is to use
scala and its shell to invoke Spark)</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>conda install -c conda-forge pyspark
</code></pre></div>
</td></tr></table>
<h1>Check that Spark server can be started OK</h1>
<p>The following starts a Spark shell (mote precisely: a scala shell with Spark
running on localhost with 2 threads, usually mapped as 1 thread per processor
core):</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nb">cd</span> spark-3.0.1-bin-hadoop3.2
./bin/spark-shell --master local<span class="o">[</span><span class="m">2</span><span class="o">]</span>
</code></pre></div>
</td></tr></table>
<p>Using the scala REPL shell requires knowledge of scala to be productive. It is
probably easier at this point to close that shell, using either <code>:q</code> or
<code>sys.exit</code>.</p>
<h1>Check that Spark can run <em>scala</em> jobs</h1>
<p>Run the "classic" Spark example of estimating <code>pi</code> based on estimating the area
of a disk of unit radius (which is <code>pi</code> by definition).</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>./bin/spark-submit <span class="se">\</span>
  --class org.apache.spark.examples.SparkPi <span class="se">\</span>
  --master local<span class="o">[</span><span class="m">2</span><span class="o">]</span> <span class="se">\</span>
  ./examples/jars/spark-examples_2.12-3.0.1.jar <span class="se">\</span>
  <span class="m">10</span>
</code></pre></div>
</td></tr></table>
<h1>Check that Spark can run <em>python</em> jobs</h1>
<p>It might be easier to use the pyspark included in the Spark distribution to
interact with Spark directly, using python rather than scala. The equivalent
invocation of the Python-based SparkPi example is</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>./bin/spark-submit examples/src/main/python/pi.py <span class="m">10</span>
</code></pre></div>
</td></tr></table>
<p>where <code>spark-submit</code> uses <code>pyspark</code> behind the scenes to handle python-based
jobs.</p>
<p>Indeed, <code>pyspark</code> can be used more directly to provide a python shell that can
be used to start and stop Spark and to control its operations:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>./bin/pyspark --master local<span class="o">[</span><span class="m">2</span><span class="o">]</span>
</code></pre></div>
</td></tr></table>
<p>Or you can use the pyspark installed using conda:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>pyspark
</code></pre></div>
</td></tr></table>
<p>See screen shot of pyspark shell below.</p>
<figure>
  <img src="files/pyspark.png" alt="" width="80%" >
  <figcaption>pyspark screenshot, before python commands are added in this shell.</figcaption>
</figure>

<p>You can issue python commands as usual, but also have access to the Spark API,
to create a Spark instance and interact with the SparkContext object.</p>
<h1>Spark dataframe examples</h1>
<p>Like python, Spark has "borrowed" the dataframe concept from R. Spark
dataframes are the preferred data structure for most users, because they
support a richer set of operations than either RDDs or Datasets.</p>
<p>The following example shows how Spark can create a dataframe object, change it
and display the results of that change.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>./bin/spark-submit examples/src/main/python/ml/sql_transformer.py
</code></pre></div>
</td></tr></table>
<p>We have created a <a href="files/sparkDfExample.ipynb">Jupyter notebook</a> (right click
and "Save As" to use) that takes those basic operations, and shows how data from
a Spark context (which "lives" in the HDFS data store that Spark uses, and
hence has been distributed across multiple nodes (in this case, the nodes are
virtual)) can be read into a pandas (in-memory) dataframe, subjected to more
changes, and written back as a Spark dataframe. The notebook has been annotated
to explain what is going on.</p>
		
		<ul class="pager">
			
			<li class="previous"><a href="00-Outline.html">&larr; Previous (Outline)</a></li>
			
			
			
			<li class="next disabled"><a>Next &rarr;</a></li>
			
		</ul>

	</div>
	
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="../../../style/bootstrap/js/bootstrap.min.js"></script>
	
  </body>
</html>